{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXfIo-Xajv7W"
      },
      "source": [
        "### OBJECTIVE\n",
        "To develop a CNN-based model for detecting brain tumours in MRI images.\n",
        "\n",
        "### BACKGROUND\n",
        "Brain tumours are a serious medical condition that can lead to significant health consequences if not diagnosed and treated promptly. With the increasing volume of medical imaging data, deep learning models, specifically CNNs, have shown great promise in classifying medical images, including MRI scans of brain tumors. The ability to automate the detection of brain tumours can save valuable time in healthcare and improve patient outcomes.\n",
        "### DATA\n",
        "The dataset consists of MRI images for brain tumour classification.\n",
        "https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
        "\n",
        "\n",
        "### METHOD\n",
        "The model preprocesses MRI images by resizing them to 150x150 pixels and normalising pixel values. The training data is augmented with rotations, shifts and flips to improve generalisation, while the validation and test data is only rescaled.\n",
        "\n",
        "A CNN is designed with convolutional, pooling, batch normalisation and dropout layers. The model is built using the Adam optimiser and categorical cross-entropy loss. Hyperparameters such as learning rate and dropout rate are tuned using TensorBoard logging and performance is evaluated using accuracy, precision and recall metrics.\n",
        "\n",
        "Finally, the performance of the model is evaluated using a confusion matrix and a classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBmqv-l2Mlo-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPooling2D, AveragePooling2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSt7Qse9ZaAA",
        "outputId": "1174e44e-85b8-4dc5-a434-f5c523074bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the file from the source to the current directory\n",
        "!cp /content/drive/MyDrive/brain-tumor-mri-dataset_merged_vordsustatud.zip /content\n",
        "\n",
        "# Unzip the file\n",
        "!unzip brain-tumor-mri-dataset_merged_vordsustatud.zip"
      ],
      "metadata": {
        "id": "nLRPneDP6HdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMTz-VKt6UD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f0f97e-3983-4779-f88c-ab80cd245e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3201 images belonging to 2 classes.\n",
            "Found 421 images belonging to 2 classes.\n",
            "Found 407 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,             # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,          # Random rotations\n",
        "    width_shift_range=0.2,      # Random horizontal shifts\n",
        "    height_shift_range=0.2,     # Random vertical shifts\n",
        "    shear_range=0.2,            # Shear transformations\n",
        "    zoom_range=0.2,             # Random zoom\n",
        "    horizontal_flip=True,       # Flip images horizontally\n",
        "    fill_mode='nearest'         # Fill pixels after transformations\n",
        ")\n",
        "\n",
        "# Validation and test data: No augmentation, only rescaling\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Define directories (ensure your data is structured correctly)\n",
        "train_dir = '/content/brain-tumor-mri-dataset_merged_vordsustatud/Training'\n",
        "val_dir = '/content/brain-tumor-mri-dataset_merged_vordsustatud/Validation'\n",
        "test_dir = '/content/brain-tumor-mri-dataset_merged_vordsustatud/Testing'\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),    # Image size must match the model input\n",
        "    batch_size=32,             # Number of images per batch\n",
        "    class_mode='categorical'   # Adjust for multi-class classification\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False              # No shuffling for consistent test results\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Juyd7fNm6Mzu"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def test_confusion_matrix(model):\n",
        "  predictions = model.predict(test_generator)\n",
        "\n",
        "  predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "  true_labels = test_generator.classes\n",
        "  print(test_generator.class_indices)\n",
        "\n",
        "  accuracy = accuracy_score(true_labels, predicted_classes)\n",
        "  print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "  print(classification_report(true_labels, predicted_classes))\n",
        "\n",
        "  print(confusion_matrix(true_labels, predicted_classes))\n",
        "\n",
        "  return None\n",
        "\n"
      ],
      "metadata": {
        "id": "QnztENiwHI3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfyCLS-V7Hmq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "\n",
        "root_logdir = os.path.join(os.curdir, \"logs\")\n",
        "run_name = ''\n",
        "\n",
        "def get_run_logdir():\n",
        "    run_id = time.strftime(\"run_\" + run_name + \"_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaJ9dqiJsV2E"
      },
      "outputs": [],
      "source": [
        "#HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-2, 1e-3, 1e-4, 1e-1, 1e-5]))\n",
        "#HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-2, 1e-3, 1e-4]))\n",
        "#HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32, 64, ]))\n",
        "#HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.3, 0.5]))\n",
        "#HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "#METRIC_ACCURACY = 'accuracy'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-3, 1e-4]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.5, 0.7]))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "METRIC_ACCURACY = 'accuracy'"
      ],
      "metadata": {
        "id": "Yz_AHukNBB6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63pYrIwx7M_g"
      },
      "outputs": [],
      "source": [
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_LEARNING_RATE, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj2p7__6lcLQ"
      },
      "outputs": [],
      "source": [
        "def train_test_model(hparams):\n",
        "    optimizer_name = hparams[HP_OPTIMIZER]\n",
        "    learning_rate = hparams[HP_LEARNING_RATE]\n",
        "    if optimizer_name == \"adam\":\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_name == \"sgd\":\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    elif optimizer_name == 'RMSprop':\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(\"unexpected optimizer name: %r\" % (optimizer_name,))\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', padding='same',\n",
        "                            input_shape=(150, 150, 3)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "        Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\"),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "        Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(filters=384, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding=\"same\"),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='relu', input_dim=(227, 227, 1)),\n",
        "        Dropout(hparams[HP_DROPOUT]),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(hparams[HP_DROPOUT]),\n",
        "        Dense(1000, activation='relu'),\n",
        "        Dropout(hparams[HP_DROPOUT]),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "    logdir = get_run_logdir()\n",
        "    model.fit(train_generator, epochs=5, validation_data=(val_generator), callbacks=[\n",
        "        tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
        "        hp.KerasCallback(logdir, hparams)])  # log hparams\n",
        "    accuracy = model.evaluate(test_generator)\n",
        "\n",
        "    test_confusion_matrix(model)\n",
        "    plot_model_stats(model)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpTe7dOBtPp"
      },
      "outputs": [],
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    accuracy = tf.reduce_mean(accuracy)  # Convert to scalar if needed\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
        "\n",
        "\n",
        "session_num = 0\n",
        "\n",
        "# for num_units in HP_NUM_UNITS.domain.values:\n",
        "#     for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "for dropout_rate in HP_DROPOUT.domain.values:\n",
        "  for optimizer in HP_OPTIMIZER.domain.values:\n",
        "    for learning_rate in HP_LEARNING_RATE.domain.values:\n",
        "        hparams = {HP_LEARNING_RATE: learning_rate,\n",
        "        #HP_NUM_UNITS: num_units,\n",
        "        HP_DROPOUT: dropout_rate,\n",
        "        HP_OPTIMIZER: optimizer,\n",
        "        }\n",
        "        run_name = \"run-%d\" % session_num\n",
        "        print('--- Starting trial: %s' % run_name)\n",
        "        print({h.name: hparams[h] for h in hparams})\n",
        "        run('logs/hparam_tuning/' + run_name, hparams)\n",
        "        session_num += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}